{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1910456 Mir Shafayat Ahmed\n",
        "## CSC470 Introduction To Parallel Programming\n",
        "### Summer 2023.\n",
        "#### Assignment: MP0\n"
      ],
      "metadata": {
        "id": "S7aOgmQhS9UR"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cFQjepisPdK5"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shafayat1004/Parallel-Programming-Assignments/blob/main/MP0/MP0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "usNRZNT_XgUU",
        "outputId": "ffcadefa-b24d-4aee-bf33-ce7c85f8c461"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-09-06 16:24:41--  https://raw.githubusercontent.com/shafayat1004/Parallel-Programming-Assignments/main/include/wb.h\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 32799 (32K) [text/plain]\n",
            "Saving to: ‘wb.h’\n",
            "\n",
            "\rwb.h                  0%[                    ]       0  --.-KB/s               \rwb.h                100%[===================>]  32.03K  --.-KB/s    in 0.002s  \n",
            "\n",
            "2023-09-06 16:24:42 (12.8 MB/s) - ‘wb.h’ saved [32799/32799]\n",
            "\n",
            "Wed Sep  6 16:24:42 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   41C    P8     9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "Collecting git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning https://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-pjuajnen\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-pjuajnen\n",
            "  Resolved https://github.com/andreinechaev/nvcc4jupyter.git to commit 0a71d56e5dce3ff1f0dd2c47c29367629262f527\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-py3-none-any.whl size=4295 sha256=58444d5f18b22b65b4aa17bfe704494aa610cd633a93d7e3f11e7ce156cd5420\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ccn1oru4/wheels/a8/b9/18/23f8ef71ceb0f63297dd1903aedd067e6243a68ea756d6feea\n",
            "Successfully built NVCCPlugin\n",
            "Installing collected packages: NVCCPlugin\n",
            "Successfully installed NVCCPlugin-0.0.2\n",
            "created output directory at /content/src\n",
            "Out bin /content/result.out\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/shafayat1004/Parallel-Programming-Assignments/main/include/wb.h\n",
        "!nvidia-smi\n",
        "%pip install git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
        "%load_ext nvcc_plugin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i6EE6p1-l6UT",
        "outputId": "df501a3e-5527-418d-cb74-66b8c0841c26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trace main::30 There is 1 device supporting CUDA\n",
            "Trace main::37 Device 0 name: Tesla T4\n",
            "Trace main::38  Computational Capabilities: 7.5\n",
            "Trace main::40  Maximum global memory size: 15835398144\n",
            "Trace main::42  Maximum constant memory size: 65536\n",
            "Trace main::44  Maximum shared memory size per block: 49152\n",
            "Trace main::46  Maximum block dimensions: 1024 x 1024 x 64\n",
            "Trace main::49  Maximum grid dimensions: 2147483647 x 65535 x 65535\n",
            "Trace main::52  Warp size: 32\n",
            "[GPU    ] 0.000228864 Getting GPU Data.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%%cu\n",
        "#include \"/content/wb.h\"\n",
        "\n",
        "//@@ The purpose of this code is to become familiar with the submission\n",
        "//@@ process. Do not worry if you do not understand all the details of\n",
        "//@@ the code.\n",
        "\n",
        "int main(int argc, char **argv) {\n",
        "  int deviceCount;\n",
        "\n",
        "  wbArg_read(argc, argv);\n",
        "\n",
        "  cudaGetDeviceCount(&deviceCount);\n",
        "\n",
        "  wbTime_start(GPU, \"Getting GPU Data.\"); //@@ start a timer\n",
        "\n",
        "  for (int dev = 0; dev < deviceCount; dev++) {\n",
        "    cudaDeviceProp deviceProp;\n",
        "\n",
        "    cudaGetDeviceProperties(&deviceProp, dev);\n",
        "\n",
        "    if (dev == 0) {\n",
        "      if (deviceProp.major == 9999 && deviceProp.minor == 9999) {\n",
        "        wbLog(TRACE, \"No CUDA GPU has been detected\");\n",
        "        return -1;\n",
        "      } else if (deviceCount == 1) {\n",
        "        //@@ WbLog is a provided logging API (similar to Log4J).\n",
        "        //@@ The logging function wbLog takes a level which is either\n",
        "        //@@ OFF, FATAL, ERROR, WARN, INFO, DEBUG, or TRACE and a\n",
        "        //@@ message to be printed.\n",
        "        wbLog(TRACE, \"There is 1 device supporting CUDA\");\n",
        "      } else {\n",
        "        wbLog(TRACE, \"There are \", deviceCount,\n",
        "              \" devices supporting CUDA\");\n",
        "      }\n",
        "    }\n",
        "\n",
        "    wbLog(TRACE, \"Device \", dev, \" name: \", deviceProp.name);\n",
        "    wbLog(TRACE, \" Computational Capabilities: \", deviceProp.major, \".\",\n",
        "          deviceProp.minor);\n",
        "    wbLog(TRACE, \" Maximum global memory size: \",\n",
        "          deviceProp.totalGlobalMem);\n",
        "    wbLog(TRACE, \" Maximum constant memory size: \",\n",
        "          deviceProp.totalConstMem);\n",
        "    wbLog(TRACE, \" Maximum shared memory size per block: \",\n",
        "          deviceProp.sharedMemPerBlock);\n",
        "    wbLog(TRACE, \" Maximum block dimensions: \",\n",
        "          deviceProp.maxThreadsDim[0], \" x \", deviceProp.maxThreadsDim[1],\n",
        "          \" x \", deviceProp.maxThreadsDim[2]);\n",
        "    wbLog(TRACE, \" Maximum grid dimensions: \", deviceProp.maxGridSize[0],\n",
        "          \" x \", deviceProp.maxGridSize[1], \" x \",\n",
        "          deviceProp.maxGridSize[2]);\n",
        "    wbLog(TRACE, \" Warp size: \", deviceProp.warpSize);\n",
        "  }\n",
        "\n",
        "  wbTime_stop(GPU, \"Getting GPU Data.\"); //@@ stop the timer\n",
        "\n",
        "  return 0;\n",
        "}"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}