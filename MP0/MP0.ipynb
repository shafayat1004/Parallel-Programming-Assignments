{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a href=\"https://colab.research.google.com/github/shafayat1004/Parallel-Programming-Assignments/blob/main/MP0/MP0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "usNRZNT_XgUU",
        "outputId": "49fcff84-b065-4c19-df39-e34d6cb6cb85"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sun Jul 23 01:31:16 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  NVIDIA A100-SXM...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P0    42W / 400W |      0MiB / 40960MiB |      0%      Default |\n",
            "|                               |                      |             Disabled |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3DLpcQ5SlyrU",
        "outputId": "edc8b112-32ee-4e1b-81d4-1eb780793917"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning https://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-ma2fwoks\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-ma2fwoks\n",
            "  Resolved https://github.com/andreinechaev/nvcc4jupyter.git to commit aac710a35f52bb78ab34d2e52517237941399eff\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-py3-none-any.whl size=4287 sha256=82d2528d4e0bc4d12116bb3a9baff2d903e8308a21978e66906398cfa8afd84b\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-dfbqq8d4/wheels/a8/b9/18/23f8ef71ceb0f63297dd1903aedd067e6243a68ea756d6feea\n",
            "Successfully built NVCCPlugin\n",
            "Installing collected packages: NVCCPlugin\n",
            "Successfully installed NVCCPlugin-0.0.2\n"
          ]
        }
      ],
      "source": [
        "%pip install git+https://github.com/andreinechaev/nvcc4jupyter.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vQgb_vPEl0RS",
        "outputId": "844d7ec2-1c9e-4555-b106-5da97e42640e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "created output directory at /content/src\n",
            "Out bin /content/result.out\n"
          ]
        }
      ],
      "source": [
        "%load_ext nvcc_plugin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AUuPGi3bl19p",
        "outputId": "6830c93c-b718-4dff-a1eb-48d2c12cde37"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing wb.h\n"
          ]
        }
      ],
      "source": [
        "%wget -p https://raw.githubusercontent.com/shafayat1004/Parallel-Programming-Assignments/main/include/wb.h"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i6EE6p1-l6UT",
        "outputId": "2b775851-8fc6-4a6b-de53-72d971b8fa1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing test.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile test.cu\n",
        "#include \"wb.h\"\n",
        "\n",
        "//@@ The purpose of this code is to become familiar with the submission\n",
        "//@@ process. Do not worry if you do not understand all the details of\n",
        "//@@ the code.\n",
        "\n",
        "int main(int argc, char **argv) {\n",
        "  int deviceCount;\n",
        "\n",
        "  wbArg_read(argc, argv);\n",
        "\n",
        "  cudaGetDeviceCount(&deviceCount);\n",
        "\n",
        "  wbTime_start(GPU, \"Getting GPU Data.\"); //@@ start a timer\n",
        "\n",
        "  for (int dev = 0; dev < deviceCount; dev++) {\n",
        "    cudaDeviceProp deviceProp;\n",
        "\n",
        "    cudaGetDeviceProperties(&deviceProp, dev);\n",
        "\n",
        "    if (dev == 0) {\n",
        "      if (deviceProp.major == 9999 && deviceProp.minor == 9999) {\n",
        "        wbLog(TRACE, \"No CUDA GPU has been detected\");\n",
        "        return -1;\n",
        "      } else if (deviceCount == 1) {\n",
        "        //@@ WbLog is a provided logging API (similar to Log4J).\n",
        "        //@@ The logging function wbLog takes a level which is either\n",
        "        //@@ OFF, FATAL, ERROR, WARN, INFO, DEBUG, or TRACE and a\n",
        "        //@@ message to be printed.\n",
        "        wbLog(TRACE, \"There is 1 device supporting CUDA\");\n",
        "      } else {\n",
        "        wbLog(TRACE, \"There are \", deviceCount,\n",
        "              \" devices supporting CUDA\");\n",
        "      }\n",
        "    }\n",
        "\n",
        "    wbLog(TRACE, \"Device \", dev, \" name: \", deviceProp.name);\n",
        "    wbLog(TRACE, \" Computational Capabilities: \", deviceProp.major, \".\",\n",
        "          deviceProp.minor);\n",
        "    wbLog(TRACE, \" Maximum global memory size: \",\n",
        "          deviceProp.totalGlobalMem);\n",
        "    wbLog(TRACE, \" Maximum constant memory size: \",\n",
        "          deviceProp.totalConstMem);\n",
        "    wbLog(TRACE, \" Maximum shared memory size per block: \",\n",
        "          deviceProp.sharedMemPerBlock);\n",
        "    wbLog(TRACE, \" Maximum block dimensions: \",\n",
        "          deviceProp.maxThreadsDim[0], \" x \", deviceProp.maxThreadsDim[1],\n",
        "          \" x \", deviceProp.maxThreadsDim[2]);\n",
        "    wbLog(TRACE, \" Maximum grid dimensions: \", deviceProp.maxGridSize[0],\n",
        "          \" x \", deviceProp.maxGridSize[1], \" x \",\n",
        "          deviceProp.maxGridSize[2]);\n",
        "    wbLog(TRACE, \" Warp size: \", deviceProp.warpSize);\n",
        "  }\n",
        "\n",
        "  wbTime_stop(GPU, \"Getting GPU Data.\"); //@@ stop the timer\n",
        "\n",
        "  return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K6Mg9vpNl8yh"
      },
      "outputs": [],
      "source": [
        "!nvcc test.cu -o test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MvWd-oUSl-sp",
        "outputId": "162e99f2-4d51-477a-8d21-979f407e666a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trace main::30 There is 1 device supporting CUDA\n",
            "Trace main::37 Device 0 name: NVIDIA A100-SXM4-40GB\n",
            "Trace main::38  Computational Capabilities: 8.0\n",
            "Trace main::40  Maximum global memory size: 42481549312\n",
            "Trace main::42  Maximum constant memory size: 65536\n",
            "Trace main::44  Maximum shared memory size per block: 49152\n",
            "Trace main::46  Maximum block dimensions: 1024 x 1024 x 64\n",
            "Trace main::49  Maximum grid dimensions: 2147483647 x 65535 x 65535\n",
            "Trace main::52  Warp size: 32\n",
            "[GPU    ] 0.000190976 Getting GPU Data.\n"
          ]
        }
      ],
      "source": [
        "!./test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tfKPG0g8X26C"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
