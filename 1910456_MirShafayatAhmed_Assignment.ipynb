{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S7aOgmQhS9UR"
      },
      "source": [
        "# 1910456 Mir Shafayat Ahmed\n",
        "## CSC470 Introduction To Parallel Programming\n",
        "### Summer 2023 Assignment\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cFQjepisPdK5"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shafayat1004/Parallel-Programming-Assignments/blob/main/1910456_MirShafayatAhmed_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "usNRZNT_XgUU",
        "outputId": "a9493701-dfb3-49af-a53d-c523070f233a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'Parallel-Programming-Assignments'...\n",
            "remote: Enumerating objects: 151, done.\u001b[K\n",
            "remote: Counting objects: 100% (151/151), done.\u001b[K\n",
            "remote: Compressing objects: 100% (136/136), done.\u001b[K\n",
            "remote: Total 151 (delta 10), reused 151 (delta 10), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (151/151), 1.50 MiB | 12.13 MiB/s, done.\n",
            "Resolving deltas: 100% (10/10), done.\n",
            "Collecting git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning https://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-qi2sqrvi\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-qi2sqrvi\n",
            "  Resolved https://github.com/andreinechaev/nvcc4jupyter.git to commit 0a71d56e5dce3ff1f0dd2c47c29367629262f527\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-py3-none-any.whl size=4295 sha256=8c2f36ea869580bb7698e8640b9538a9b9a2e5a380816deb5811b1a48c281727\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-6j97_77p/wheels/a8/b9/18/23f8ef71ceb0f63297dd1903aedd067e6243a68ea756d6feea\n",
            "Successfully built NVCCPlugin\n",
            "Installing collected packages: NVCCPlugin\n",
            "Successfully installed NVCCPlugin-0.0.2\n",
            "Thu Sep  7 04:27:42 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   66C    P8    11W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/shafayat1004/Parallel-Programming-Assignments.git\n",
        "%pip install git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5fgfcuCBB0G",
        "outputId": "7ac5a58a-56ef-49ec-f69f-203d0c8b3321"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "created output directory at /content/src\n",
            "Out bin /content/result.out\n"
          ]
        }
      ],
      "source": [
        "%load_ext nvcc_plugin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_and_run (assignment_no: int, no_of_test_cases: int):\n",
        "    !nvcc mp{assignment_no}.cu -o mp{assignment_no}\n",
        "\n",
        "    print(f\"Running MP{assignment_no}\")\n",
        "    print(\"\\n======================================================================\")\n",
        "\n",
        "    if no_of_test_cases > 0:\n",
        "        for i in range(no_of_test_cases):\n",
        "            print(f\"Test Case {i}:\")\n",
        "            print(\"----------------\")\n",
        "            !./mp{assignment_no} /content/Parallel-Programming-Assignments/MP{assignment_no}/data/{i}/*\n",
        "    else:\n",
        "        !./mp{assignment_no}\n",
        "    \n",
        "    print(\"======================================================================\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## MP0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile mp0.cu\n",
        "#include \"/content/Parallel-Programming-Assignments/include/wb.h\"\n",
        "\n",
        "//@@ The purpose of this code is to become familiar with the submission\n",
        "//@@ process. Do not worry if you do not understand all the details of\n",
        "//@@ the code.\n",
        "\n",
        "int main(int argc, char **argv) {\n",
        "    int deviceCount;\n",
        "\n",
        "    wbArg_read(argc, argv);\n",
        "\n",
        "    cudaGetDeviceCount(&deviceCount);\n",
        "\n",
        "    wbTime_start(GPU, \"Getting GPU Data.\"); //@@ start a timer\n",
        "\n",
        "    for (int dev = 0; dev < deviceCount; dev++) {\n",
        "        cudaDeviceProp deviceProp;\n",
        "\n",
        "        cudaGetDeviceProperties(&deviceProp, dev);\n",
        "\n",
        "        if (dev == 0) {\n",
        "            if (deviceProp.major == 9999 && deviceProp.minor == 9999) {\n",
        "                wbLog(TRACE, \"No CUDA GPU has been detected\");\n",
        "                return -1;\n",
        "            } else if (deviceCount == 1) {\n",
        "                //@@ WbLog is a provided logging API (similar to Log4J).\n",
        "                //@@ The logging function wbLog takes a level which is either\n",
        "                //@@ OFF, FATAL, ERROR, WARN, INFO, DEBUG, or TRACE and a\n",
        "                //@@ message to be printed.\n",
        "                wbLog(TRACE, \"There is 1 device supporting CUDA\");\n",
        "            } else {\n",
        "                wbLog(TRACE, \"There are \", deviceCount,\n",
        "                    \" devices supporting CUDA\");\n",
        "            }\n",
        "        }\n",
        "\n",
        "        wbLog(TRACE, \"Device \", dev, \" name: \", deviceProp.name);\n",
        "        wbLog(TRACE, \" Computational Capabilities: \", deviceProp.major, \".\",\n",
        "            deviceProp.minor);\n",
        "        wbLog(TRACE, \" Maximum global memory size: \",\n",
        "            deviceProp.totalGlobalMem);\n",
        "        wbLog(TRACE, \" Maximum constant memory size: \",\n",
        "            deviceProp.totalConstMem);\n",
        "        wbLog(TRACE, \" Maximum shared memory size per block: \",\n",
        "            deviceProp.sharedMemPerBlock);\n",
        "        wbLog(TRACE, \" Maximum block dimensions: \",\n",
        "            deviceProp.maxThreadsDim[0], \" x \", deviceProp.maxThreadsDim[1],\n",
        "            \" x \", deviceProp.maxThreadsDim[2]);\n",
        "        wbLog(TRACE, \" Maximum grid dimensions: \", deviceProp.maxGridSize[0],\n",
        "            \" x \", deviceProp.maxGridSize[1], \" x \",\n",
        "            deviceProp.maxGridSize[2]);\n",
        "        wbLog(TRACE, \" Warp size: \", deviceProp.warpSize);\n",
        "    }\n",
        "\n",
        "    wbTime_stop(GPU, \"Getting GPU Data.\"); //@@ stop the timer\n",
        "\n",
        "    return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "assignment = 0\n",
        "\n",
        "!nvcc mp{assignment}.cu -o mp{assignment}\n",
        "print(f\"Running MP{assignment}\")\n",
        "!./mp{assignment}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## MP1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i6EE6p1-l6UT",
        "outputId": "58f82e8b-1f1b-4e7f-ac0f-7362470f115e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting mp1.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile mp1.cu\n",
        "#include \"/content/Parallel-Programming-Assignments/include/wb.h\"\n",
        "\n",
        "__global__ void vecAdd(float *in1, float *in2, float *out, int len) {\n",
        "\tint idx = blockIdx.x*blockDim.x + threadIdx.x;\n",
        "\tif (idx < len)\n",
        "\t\tout[idx] = in1[idx] + in2[idx];\n",
        "}\n",
        "\n",
        "int main(int argc, char **argv) {\n",
        "\twbArg_t args;\n",
        "\tint inputLength;\n",
        "\tfloat *hostInput1;\n",
        "\tfloat *hostInput2;\n",
        "\tfloat *hostOutput;\n",
        "\tfloat *deviceInput1;\n",
        "\tfloat *deviceInput2;\n",
        "\tfloat *deviceOutput;\n",
        "\n",
        "\targs = wbArg_read(argc, argv);\n",
        "\n",
        "\twbTime_start(Generic, \"Importing data and creating memory on host\");\n",
        "\thostInput1 = (float *)wbImport(wbArg_getInputFile(args, 0), &inputLength);\n",
        "\thostInput2 = (float *)wbImport(wbArg_getInputFile(args, 1), &inputLength);\n",
        "\thostOutput = (float *)malloc(inputLength * sizeof(float));\n",
        "\twbTime_stop(Generic, \"Importing data and creating memory on host\");\n",
        "\n",
        "\twbLog(TRACE, \"The input length is \", inputLength);\n",
        "\n",
        "\tint size = inputLength * sizeof(float);\n",
        "\n",
        "\twbTime_start(GPU, \"Allocating GPU memory.\");\n",
        "\tcudaMalloc((void **)&deviceInput1, size);\n",
        "\tcudaMalloc((void **)&deviceInput2, size);\n",
        "\tcudaMalloc((void **)&deviceOutput, size);\n",
        "\twbTime_stop(GPU, \"Allocating GPU memory.\");\n",
        "\n",
        "\twbTime_start(GPU, \"Copying input memory to the GPU.\");\n",
        "\tcudaMemcpy(deviceInput1, hostInput1, size, cudaMemcpyHostToDevice);\n",
        "\tcudaMemcpy(deviceInput2, hostInput2, size, cudaMemcpyHostToDevice);\n",
        "\twbTime_stop(GPU, \"Copying input memory to the GPU.\");\n",
        "\n",
        "\tdim3 DimGrid((inputLength - 1) / 256 + 1, 1, 1);\n",
        "\tdim3 DimBlock(256, 1, 1);\n",
        "\n",
        "\twbTime_start(Compute, \"Performing CUDA computation\");\n",
        "\tvecAdd << <DimGrid, DimBlock >> >(deviceInput1, deviceInput2, deviceOutput, inputLength);\n",
        "\n",
        "\tcudaDeviceSynchronize();\n",
        "\twbTime_stop(Compute, \"Performing CUDA computation\");\n",
        "\n",
        "\twbTime_start(Copy, \"Copying output memory to the CPU\");\n",
        "\tcudaMemcpy(hostOutput, deviceOutput, size, cudaMemcpyDeviceToHost);\n",
        "\twbTime_stop(Copy, \"Copying output memory to the CPU\");\n",
        "\n",
        "\twbTime_start(GPU, \"Freeing GPU Memory\");\n",
        "\tcudaFree(deviceInput1);\n",
        "\tcudaFree(deviceInput2);\n",
        "\tcudaFree(deviceOutput);\n",
        "\twbTime_stop(GPU, \"Freeing GPU Memory\");\n",
        "\n",
        "\twbSolution(args, hostOutput, inputLength);\n",
        "\n",
        "\tfree(hostInput1);\n",
        "\tfree(hostInput2);\n",
        "\tfree(hostOutput);\n",
        "\n",
        "\treturn 0;\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yO-R3Rbi_fWF",
        "outputId": "7308a2a1-8921-4e9f-8fc4-a36c566453be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "Test Case 0:\n",
            "----------------\n",
            "[Generic] 0.000167936 Importing data and creating memory on host\n",
            "Trace main::27 The input length is 64\n",
            "[GPU    ] 0.000166144 Allocating GPU memory.\n",
            "[GPU    ] 0.000039936 Copying input memory to the GPU.\n",
            "[Compute] 0.000026112 Performing CUDA computation\n",
            "[Copy   ] 0.000018944 Copying output memory to the CPU\n",
            "[GPU    ] 0.000106752 Freeing GPU Memory\n",
            "Solution is correct.\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "Test Case 1:\n",
            "----------------\n",
            "[Generic] 0.000237056 Importing data and creating memory on host\n",
            "Trace main::27 The input length is 128\n",
            "[GPU    ] 0.000142848 Allocating GPU memory.\n",
            "[GPU    ] 0.000045056 Copying input memory to the GPU.\n",
            "[Compute] 0.000029184 Performing CUDA computation\n",
            "[Copy   ] 0.000020992 Copying output memory to the CPU\n",
            "[GPU    ] 0.000108032 Freeing GPU Memory\n",
            "Solution is correct.\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "Test Case 2:\n",
            "----------------\n",
            "[Generic] 0.000215040 Importing data and creating memory on host\n",
            "Trace main::27 The input length is 56\n",
            "[GPU    ] 0.000130048 Allocating GPU memory.\n",
            "[GPU    ] 0.000040960 Copying input memory to the GPU.\n",
            "[Compute] 0.000027904 Performing CUDA computation\n",
            "[Copy   ] 0.000017920 Copying output memory to the CPU\n",
            "[GPU    ] 0.000102144 Freeing GPU Memory\n",
            "Solution is correct.\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "Test Case 3:\n",
            "----------------\n",
            "[Generic] 0.000225024 Importing data and creating memory on host\n",
            "Trace main::27 The input length is 100\n",
            "[GPU    ] 0.000132096 Allocating GPU memory.\n",
            "[GPU    ] 0.000048128 Copying input memory to the GPU.\n",
            "[Compute] 0.000032000 Performing CUDA computation\n",
            "[Copy   ] 0.000024832 Copying output memory to the CPU\n",
            "[GPU    ] 0.000129792 Freeing GPU Memory\n",
            "Solution is correct.\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "Test Case 4:\n",
            "----------------\n",
            "[Generic] 0.000338944 Importing data and creating memory on host\n",
            "Trace main::27 The input length is 256\n",
            "[GPU    ] 0.000129024 Allocating GPU memory.\n",
            "[GPU    ] 0.000041984 Copying input memory to the GPU.\n",
            "[Compute] 0.000032000 Performing CUDA computation\n",
            "[Copy   ] 0.000018944 Copying output memory to the CPU\n",
            "[GPU    ] 0.000098048 Freeing GPU Memory\n",
            "Solution is correct.\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "Test Case 5:\n",
            "----------------\n",
            "[Generic] 0.000205056 Importing data and creating memory on host\n",
            "Trace main::27 The input length is 130\n",
            "[GPU    ] 0.000129024 Allocating GPU memory.\n",
            "[GPU    ] 0.000041984 Copying input memory to the GPU.\n",
            "[Compute] 0.000029952 Performing CUDA computation\n",
            "[Copy   ] 0.000019968 Copying output memory to the CPU\n",
            "[GPU    ] 0.000100864 Freeing GPU Memory\n",
            "Solution is correct.\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "Test Case 6:\n",
            "----------------\n",
            "[Generic] 0.000177920 Importing data and creating memory on host\n",
            "Trace main::27 The input length is 90\n",
            "[GPU    ] 0.000131840 Allocating GPU memory.\n",
            "[GPU    ] 0.000034816 Copying input memory to the GPU.\n",
            "[Compute] 0.000026112 Performing CUDA computation\n",
            "[Copy   ] 0.000018944 Copying output memory to the CPU\n",
            "[GPU    ] 0.000099840 Freeing GPU Memory\n",
            "Solution is correct.\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "Test Case 7:\n",
            "----------------\n",
            "[Generic] 0.000535808 Importing data and creating memory on host\n",
            "Trace main::27 The input length is 512\n",
            "[GPU    ] 0.000169984 Allocating GPU memory.\n",
            "[GPU    ] 0.000039936 Copying input memory to the GPU.\n",
            "[Compute] 0.000030976 Performing CUDA computation\n",
            "[Copy   ] 0.000019968 Copying output memory to the CPU\n",
            "[GPU    ] 0.000105216 Freeing GPU Memory\n",
            "Solution is correct.\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "Test Case 8:\n",
            "----------------\n",
            "[Generic] 0.000211968 Importing data and creating memory on host\n",
            "Trace main::27 The input length is 90\n",
            "[GPU    ] 0.000134912 Allocating GPU memory.\n",
            "[GPU    ] 0.000038912 Copying input memory to the GPU.\n",
            "[Compute] 0.000036096 Performing CUDA computation\n",
            "[Copy   ] 0.000022016 Copying output memory to the CPU\n",
            "[GPU    ] 0.000103936 Freeing GPU Memory\n",
            "Solution is correct.\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "Test Case 9:\n",
            "----------------\n",
            "[Generic] 0.000366848 Importing data and creating memory on host\n",
            "Trace main::27 The input length is 123\n",
            "[GPU    ] 0.000172032 Allocating GPU memory.\n",
            "[GPU    ] 0.000050944 Copying input memory to the GPU.\n",
            "[Compute] 0.000029952 Performing CUDA computation\n",
            "[Copy   ] 0.000026880 Copying output memory to the CPU\n",
            "[GPU    ] 0.000140032 Freeing GPU Memory\n",
            "Solution is correct.\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "assignment = 1\n",
        "!nvcc mp{assignment}.cu -o mp{assignment}\n",
        "\n",
        "for i in range(10):\n",
        "  print(f\"Running MP{assignment}\")\n",
        "  print(\"\\n======================================================================\")\n",
        "  print(f\"Test Case {i}:\")\n",
        "  print(\"----------------\")\n",
        "  !./mp1 /content/Parallel-Programming-Assignments/MP1/data/{i}/*\n",
        "  print(\"======================================================================\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## MP2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile mp2.cu\n",
        "#include \"/content/Parallel-Programming-Assignments/include/wb.h\"\n",
        "\n",
        "#define wbCheck(stmt)                                                     \\\n",
        "  do {                                                                    \\\n",
        "    cudaError_t err = stmt;                                               \\\n",
        "    if (err != cudaSuccess) {                                             \\\n",
        "      wbLog(ERROR, \"Failed to run stmt \", #stmt);                         \\\n",
        "      wbLog(ERROR, \"Got CUDA error ...  \", cudaGetErrorString(err));      \\\n",
        "      return -1;                                                          \\\n",
        "    }                                                                     \\\n",
        "  } while (0)\n",
        "\n",
        "// Compute C = A * B\n",
        "__global__ void matrixMultiply(float *A, float *B, float *C, int numARows,\n",
        "                               int numAColumns, int numBRows,\n",
        "                               int numBColumns, int numCRows,\n",
        "                               int numCColumns) {\n",
        "  //@@ Insert code to implement matrix multiplication here\n",
        "}\n",
        "\n",
        "int main(int argc, char **argv) {\n",
        "  wbArg_t args;\n",
        "  float *hostA; // The A matrix\n",
        "  float *hostB; // The B matrix\n",
        "  float *hostC; // The output C matrix\n",
        "  float *deviceA;\n",
        "  float *deviceB;\n",
        "  float *deviceC;\n",
        "  int numARows;    // number of rows in the matrix A\n",
        "  int numAColumns; // number of columns in the matrix A\n",
        "  int numBRows;    // number of rows in the matrix B\n",
        "  int numBColumns; // number of columns in the matrix B\n",
        "  int numCRows;    // number of rows in the matrix C (you have to set this)\n",
        "  int numCColumns; // number of columns in the matrix C (you have to set\n",
        "                   // this)\n",
        "\n",
        "  args = wbArg_read(argc, argv);\n",
        "\n",
        "  wbTime_start(Generic, \"Importing data and creating memory on host\");\n",
        "  hostA = (float *)wbImport(wbArg_getInputFile(args, 0), &numARows,\n",
        "                            &numAColumns);\n",
        "  hostB = (float *)wbImport(wbArg_getInputFile(args, 1), &numBRows,\n",
        "                            &numBColumns);\n",
        "  //@@ Set numCRows and numCColumns\n",
        "  numCRows = 0;\n",
        "  numCColumns = 0;\n",
        "  //@@ Allocate the hostC matrix\n",
        "  wbTime_stop(Generic, \"Importing data and creating memory on host\");\n",
        "\n",
        "  wbLog(TRACE, \"The dimensions of A are \", numARows, \" x \", numAColumns);\n",
        "  wbLog(TRACE, \"The dimensions of B are \", numBRows, \" x \", numBColumns);\n",
        "\n",
        "  wbTime_start(GPU, \"Allocating GPU memory.\");\n",
        "  //@@ Allocate GPU memory here\n",
        "\n",
        "  wbTime_stop(GPU, \"Allocating GPU memory.\");\n",
        "\n",
        "  wbTime_start(GPU, \"Copying input memory to the GPU.\");\n",
        "  //@@ Copy memory to the GPU here\n",
        "\n",
        "  wbTime_stop(GPU, \"Copying input memory to the GPU.\");\n",
        "\n",
        "  //@@ Initialize the grid and block dimensions here\n",
        "\n",
        "  wbTime_start(Compute, \"Performing CUDA computation\");\n",
        "  //@@ Launch the GPU Kernel here\n",
        "\n",
        "  cudaDeviceSynchronize();\n",
        "  wbTime_stop(Compute, \"Performing CUDA computation\");\n",
        "\n",
        "  wbTime_start(Copy, \"Copying output memory to the CPU\");\n",
        "  //@@ Copy the GPU memory back to the CPU here\n",
        "\n",
        "  wbTime_stop(Copy, \"Copying output memory to the CPU\");\n",
        "\n",
        "  wbTime_start(GPU, \"Freeing GPU Memory\");\n",
        "  //@@ Free the GPU memory here\n",
        "\n",
        "  wbTime_stop(GPU, \"Freeing GPU Memory\");\n",
        "\n",
        "  wbSolution(args, hostC, numCRows, numCColumns);\n",
        "\n",
        "  free(hostA);\n",
        "  free(hostB);\n",
        "  free(hostC);\n",
        "\n",
        "  return 0;\n",
        "}\n",
        "\n",
        "\n",
        "  wbTime_stop(GPU, \"Freeing GPU Memory\");\n",
        "\n",
        "  wbSolution(args, hostC, numCRows, numCColumns);\n",
        "\n",
        "  free(hostA);\n",
        "  free(hostB);\n",
        "  free(hostC);\n",
        "\n",
        "  return 0;\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "assignment = 2\n",
        "!nvcc mp{assignment}.cu -o mp{assignment}\n",
        "\n",
        "for i in range(10):\n",
        "  print(f\"Running MP{assignment}\")\n",
        "  print(\"\\n======================================================================\")\n",
        "  print(f\"Test Case {i}:\")\n",
        "  print(\"----------------\")\n",
        "  !./mp1 /content/Parallel-Programming-Assignments/MP1/data/{i}/*\n",
        "  print(\"======================================================================\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## MP3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile mp3.cu\n",
        "#include \"/content/Parallel-Programming-Assignments/include/wb.h\"\n",
        "\n",
        "#define wbCheck(stmt)                                                     \\\n",
        "  do {                                                                    \\\n",
        "    cudaError_t err = stmt;                                               \\\n",
        "    if (err != cudaSuccess) {                                             \\\n",
        "      wbLog(ERROR, \"Failed to run stmt \", #stmt);                         \\\n",
        "      wbLog(ERROR, \"Got CUDA error ...  \", cudaGetErrorString(err));      \\\n",
        "      return -1;                                                          \\\n",
        "    }                                                                     \\\n",
        "  } while (0)\n",
        "\n",
        "// Compute C = A * B\n",
        "__global__ void matrixMultiply(float *A, float *B, float *C, int numARows,\n",
        "                               int numAColumns, int numBRows,\n",
        "                               int numBColumns, int numCRows,\n",
        "                               int numCColumns) {\n",
        "  //@@ Insert code to implement matrix multiplication here\n",
        "}\n",
        "\n",
        "int main(int argc, char **argv) {\n",
        "    wbArg_t args;\n",
        "    float *hostA; // The A matrix\n",
        "    float *hostB; // The B matrix\n",
        "    float *hostC; // The output C matrix\n",
        "    float *deviceA;\n",
        "    float *deviceB;\n",
        "    float *deviceC;\n",
        "    int numARows;    // number of rows in the matrix A\n",
        "    int numAColumns; // number of columns in the matrix A\n",
        "    int numBRows;    // number of rows in the matrix B\n",
        "    int numBColumns; // number of columns in the matrix B\n",
        "    int numCRows;    // number of rows in the matrix C (you have to set this)\n",
        "    int numCColumns; // number of columns in the matrix C (you have to set\n",
        "                    // this)\n",
        "\n",
        "    args = wbArg_read(argc, argv);\n",
        "\n",
        "    wbTime_start(Generic, \"Importing data and creating memory on host\");\n",
        "    hostA = (float *)wbImport(wbArg_getInputFile(args, 0), &numARows,\n",
        "                                &numAColumns);\n",
        "    hostB = (float *)wbImport(wbArg_getInputFile(args, 1), &numBRows,\n",
        "                                &numBColumns);\n",
        "    //@@ Set numCRows and numCColumns\n",
        "    numCRows = 0;\n",
        "    numCColumns = 0;\n",
        "    //@@ Allocate the hostC matrix\n",
        "    wbTime_stop(Generic, \"Importing data and creating memory on host\");\n",
        "\n",
        "    wbLog(TRACE, \"The dimensions of A are \", numARows, \" x \", numAColumns);\n",
        "    wbLog(TRACE, \"The dimensions of B are \", numBRows, \" x \", numBColumns);\n",
        "\n",
        "    wbTime_start(GPU, \"Allocating GPU memory.\");\n",
        "    //@@ Allocate GPU memory here\n",
        "\n",
        "    wbTime_stop(GPU, \"Allocating GPU memory.\");\n",
        "\n",
        "    wbTime_start(GPU, \"Copying input memory to the GPU.\");\n",
        "    //@@ Copy memory to the GPU here\n",
        "\n",
        "    wbTime_stop(GPU, \"Copying input memory to the GPU.\");\n",
        "\n",
        "    //@@ Initialize the grid and block dimensions here\n",
        "\n",
        "    wbTime_start(Compute, \"Performing CUDA computation\");\n",
        "    //@@ Launch the GPU Kernel here\n",
        "\n",
        "    cudaDeviceSynchronize();\n",
        "    wbTime_stop(Compute, \"Performing CUDA computation\");\n",
        "\n",
        "    wbTime_start(Copy, \"Copying output memory to the CPU\");\n",
        "    //@@ Copy the GPU memory back to the CPU here\n",
        "\n",
        "    wbTime_stop(Copy, \"Copying output memory to the CPU\");\n",
        "\n",
        "    wbTime_start(GPU, \"Freeing GPU Memory\");\n",
        "    //@@ Free the GPU memory here\n",
        "\n",
        "    wbTime_stop(GPU, \"Freeing GPU Memory\");\n",
        "\n",
        "    wbSolution(args, hostC, numCRows, numCColumns);\n",
        "\n",
        "    free(hostA);\n",
        "    free(hostB);\n",
        "    free(hostC);\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "assignment = 3\n",
        "!nvcc mp{assignment}.cu -o mp{assignment}\n",
        "\n",
        "for i in range(10):\n",
        "  print(f\"Running MP{assignment}\")\n",
        "  print(\"\\n======================================================================\")\n",
        "  print(f\"Test Case {i}:\")\n",
        "  print(\"----------------\")\n",
        "  !./mp1 /content/Parallel-Programming-Assignments/MP1/data/{i}/*\n",
        "  print(\"======================================================================\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## MP4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile mp4.cu\n",
        "#include \"/content/Parallel-Programming-Assignments/include/wb.h\"\n",
        "\n",
        "#define wbCheck(stmt)                                                     \\\n",
        "  do {                                                                    \\\n",
        "    cudaError_t err = stmt;                                               \\\n",
        "    if (err != cudaSuccess) {                                             \\\n",
        "      wbLog(ERROR, \"CUDA error: \", cudaGetErrorString(err));              \\\n",
        "      wbLog(ERROR, \"Failed to run stmt \", #stmt);                         \\\n",
        "      return -1;                                                          \\\n",
        "    }                                                                     \\\n",
        "  } while (0)\n",
        "\n",
        "//@@ Define any useful program-wide constants here\n",
        "\n",
        "//@@ Define constant memory for device kernel here\n",
        "\n",
        "__global__ void conv3d(float *input, float *output, const int z_size,\n",
        "                       const int y_size, const int x_size) {\n",
        "  //@@ Insert kernel code here\n",
        "}\n",
        "\n",
        "int main(int argc, char *argv[]) {\n",
        "    wbArg_t args;\n",
        "    int z_size;\n",
        "    int y_size;\n",
        "    int x_size;\n",
        "    int inputLength, kernelLength;\n",
        "    float *hostInput;\n",
        "    float *hostKernel;\n",
        "    float *hostOutput;\n",
        "    float *deviceInput;\n",
        "    float *deviceOutput;\n",
        "\n",
        "    args = wbArg_read(argc, argv);\n",
        "\n",
        "    // Import data\n",
        "    hostInput = (float *)wbImport(wbArg_getInputFile(args, 0), &inputLength);\n",
        "    hostKernel =\n",
        "        (float *)wbImport(wbArg_getInputFile(args, 1), &kernelLength);\n",
        "    hostOutput = (float *)malloc(inputLength * sizeof(float));\n",
        "\n",
        "    // First three elements are the input dimensions\n",
        "    z_size = hostInput[0];\n",
        "    y_size = hostInput[1];\n",
        "    x_size = hostInput[2];\n",
        "    wbLog(TRACE, \"The input size is \", z_size, \"x\", y_size, \"x\", x_size);\n",
        "    assert(z_size * y_size * x_size == inputLength - 3);\n",
        "    assert(kernelLength == 27);\n",
        "\n",
        "    wbTime_start(GPU, \"Doing GPU Computation (memory + compute)\");\n",
        "\n",
        "    wbTime_start(GPU, \"Doing GPU memory allocation\");\n",
        "    //@@ Allocate GPU memory here\n",
        "    // Recall that inputLength is 3 elements longer than the input data\n",
        "    // because the first  three elements were the dimensions\n",
        "    wbTime_stop(GPU, \"Doing GPU memory allocation\");\n",
        "\n",
        "    wbTime_start(Copy, \"Copying data to the GPU\");\n",
        "    //@@ Copy input and kernel to GPU here\n",
        "    // Recall that the first three elements of hostInput are dimensions and\n",
        "    // do\n",
        "    // not need to be copied to the gpu\n",
        "    wbTime_stop(Copy, \"Copying data to the GPU\");\n",
        "\n",
        "    wbTime_start(Compute, \"Doing the computation on the GPU\");\n",
        "    //@@ Initialize grid and block dimensions here\n",
        "\n",
        "    //@@ Launch the GPU kernel here\n",
        "    cudaDeviceSynchronize();\n",
        "    wbTime_stop(Compute, \"Doing the computation on the GPU\");\n",
        "\n",
        "    wbTime_start(Copy, \"Copying data from the GPU\");\n",
        "    //@@ Copy the device memory back to the host here\n",
        "    // Recall that the first three elements of the output are the dimensions\n",
        "    // and should not be set here (they are set below)\n",
        "    wbTime_stop(Copy, \"Copying data from the GPU\");\n",
        "\n",
        "    wbTime_stop(GPU, \"Doing GPU Computation (memory + compute)\");\n",
        "\n",
        "    // Set the output dimensions for correctness checking\n",
        "    hostOutput[0] = z_size;\n",
        "    hostOutput[1] = y_size;\n",
        "    hostOutput[2] = x_size;\n",
        "    wbSolution(args, hostOutput, inputLength);\n",
        "\n",
        "    // Free device memory\n",
        "    cudaFree(deviceInput);\n",
        "    cudaFree(deviceOutput);\n",
        "\n",
        "    // Free host memory\n",
        "    free(hostInput);\n",
        "    free(hostOutput);\n",
        "    return 0;\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
