{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S7aOgmQhS9UR"
      },
      "source": [
        "# 1910456 Mir Shafayat Ahmed\n",
        "## CSC470 Introduction To Parallel Programming\n",
        "### Summer 2023 Assignment\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cFQjepisPdK5"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shafayat1004/Parallel-Programming-Assignments/blob/main/1910456_MirShafayatAhmed_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "usNRZNT_XgUU",
        "outputId": "5dbe05d0-d12c-4815-e912-d6759424ed4d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Parallel-Programming-Assignments'...\n",
            "remote: Enumerating objects: 158, done.\u001b[K\n",
            "remote: Counting objects: 100% (158/158), done.\u001b[K\n",
            "remote: Compressing objects: 100% (139/139), done.\u001b[K\n",
            "remote: Total 158 (delta 15), reused 157 (delta 14), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (158/158), 1.51 MiB | 8.18 MiB/s, done.\n",
            "Resolving deltas: 100% (15/15), done.\n",
            "Collecting git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning https://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-bpxkduuj\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-bpxkduuj\n",
            "  Resolved https://github.com/andreinechaev/nvcc4jupyter.git to commit 0a71d56e5dce3ff1f0dd2c47c29367629262f527\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-py3-none-any.whl size=4295 sha256=044a7262d9375a0821f480d98f542ba23a61acbeac9a97a12e9cb7d459515e1d\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-uu2mqloe/wheels/a8/b9/18/23f8ef71ceb0f63297dd1903aedd067e6243a68ea756d6feea\n",
            "Successfully built NVCCPlugin\n",
            "Installing collected packages: NVCCPlugin\n",
            "Successfully installed NVCCPlugin-0.0.2\n",
            "Thu Sep  7 16:36:57 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   45C    P8    10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/shafayat1004/Parallel-Programming-Assignments.git\n",
        "%pip install git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5fgfcuCBB0G",
        "outputId": "fc90515e-67e5-4393-ceca-84e15615f8d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "created output directory at /content/src\n",
            "Out bin /content/result.out\n"
          ]
        }
      ],
      "source": [
        "%load_ext nvcc_plugin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "gvqWn6TDCJtV"
      },
      "outputs": [],
      "source": [
        "def build_and_run (assignment_no: int, no_of_test_cases: int):\n",
        "    !nvcc mp{assignment_no}.cu -o mp{assignment_no}\n",
        "\n",
        "    print(f\"Running MP{assignment_no}\")\n",
        "    print(\"\\n======================================================================\")\n",
        "\n",
        "    if no_of_test_cases > 0:\n",
        "        for i in range(no_of_test_cases):\n",
        "            print(\"----------------------------------------------------------------------\")\n",
        "            print(f\"Test Case {i}:\")\n",
        "            print(\"----------------\")\n",
        "            !./mp{assignment_no} /content/Parallel-Programming-Assignments/MP{assignment_no}/data/{i}/*\n",
        "    else:\n",
        "        !./mp{assignment_no}\n",
        "\n",
        "    print(\"======================================================================\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sxr9NntDCJtV"
      },
      "source": [
        "## MP0 (Test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z2-K1JjbCJtV",
        "outputId": "972afc77-c3e7-4d80-be55-2bc4ab1f19cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing mp0.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile mp0.cu\n",
        "#include \"/content/Parallel-Programming-Assignments/include/wb.h\"\n",
        "\n",
        "//@@ The purpose of this code is to become familiar with the submission\n",
        "//@@ process. Do not worry if you do not understand all the details of\n",
        "//@@ the code.\n",
        "\n",
        "int main(int argc, char **argv) {\n",
        "    int deviceCount;\n",
        "\n",
        "    wbArg_read(argc, argv);\n",
        "\n",
        "    cudaGetDeviceCount(&deviceCount);\n",
        "\n",
        "    wbTime_start(GPU, \"Getting GPU Data.\"); //@@ start a timer\n",
        "\n",
        "    for (int dev = 0; dev < deviceCount; dev++) {\n",
        "        cudaDeviceProp deviceProp;\n",
        "\n",
        "        cudaGetDeviceProperties(&deviceProp, dev);\n",
        "\n",
        "        if (dev == 0) {\n",
        "            if (deviceProp.major == 9999 && deviceProp.minor == 9999) {\n",
        "                wbLog(TRACE, \"No CUDA GPU has been detected\");\n",
        "                return -1;\n",
        "            } else if (deviceCount == 1) {\n",
        "                //@@ WbLog is a provided logging API (similar to Log4J).\n",
        "                //@@ The logging function wbLog takes a level which is either\n",
        "                //@@ OFF, FATAL, ERROR, WARN, INFO, DEBUG, or TRACE and a\n",
        "                //@@ message to be printed.\n",
        "                wbLog(TRACE, \"There is 1 device supporting CUDA\");\n",
        "            } else {\n",
        "                wbLog(TRACE, \"There are \", deviceCount,\n",
        "                    \" devices supporting CUDA\");\n",
        "            }\n",
        "        }\n",
        "\n",
        "        wbLog(TRACE, \"Device \", dev, \" name: \", deviceProp.name);\n",
        "        wbLog(TRACE, \" Computational Capabilities: \", deviceProp.major, \".\",\n",
        "            deviceProp.minor);\n",
        "        wbLog(TRACE, \" Maximum global memory size: \",\n",
        "            deviceProp.totalGlobalMem);\n",
        "        wbLog(TRACE, \" Maximum constant memory size: \",\n",
        "            deviceProp.totalConstMem);\n",
        "        wbLog(TRACE, \" Maximum shared memory size per block: \",\n",
        "            deviceProp.sharedMemPerBlock);\n",
        "        wbLog(TRACE, \" Maximum block dimensions: \",\n",
        "            deviceProp.maxThreadsDim[0], \" x \", deviceProp.maxThreadsDim[1],\n",
        "            \" x \", deviceProp.maxThreadsDim[2]);\n",
        "        wbLog(TRACE, \" Maximum grid dimensions: \", deviceProp.maxGridSize[0],\n",
        "            \" x \", deviceProp.maxGridSize[1], \" x \",\n",
        "            deviceProp.maxGridSize[2]);\n",
        "        wbLog(TRACE, \" Warp size: \", deviceProp.warpSize);\n",
        "    }\n",
        "\n",
        "    wbTime_stop(GPU, \"Getting GPU Data.\"); //@@ stop the timer\n",
        "\n",
        "    return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "isdYZCCNCJtW",
        "outputId": "c3d38bc4-e0e3-4233-dbb7-b3ca14f248b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running MP0\n",
            "\n",
            "======================================================================\n",
            "Trace main::30 There is 1 device supporting CUDA\n",
            "Trace main::37 Device 0 name: Tesla T4\n",
            "Trace main::38  Computational Capabilities: 7.5\n",
            "Trace main::40  Maximum global memory size: 15835398144\n",
            "Trace main::42  Maximum constant memory size: 65536\n",
            "Trace main::44  Maximum shared memory size per block: 49152\n",
            "Trace main::46  Maximum block dimensions: 1024 x 1024 x 64\n",
            "Trace main::49  Maximum grid dimensions: 2147483647 x 65535 x 65535\n",
            "Trace main::52  Warp size: 32\n",
            "[GPU    ] 0.000294912 Getting GPU Data.\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "build_and_run(assignment_no = 0, no_of_test_cases = 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K4Vv1jKmCJtW"
      },
      "source": [
        "## MP1 (Vector Addition)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Objective\n",
        "\n",
        "The purpose of this lab is for you to become familiar with using the CUDA API by implementing a simple vector addition kernel\n",
        "and its associated host code as shown in the lectures.\n",
        "\n",
        "### Prerequisites\n",
        "\n",
        "Before starting this lab, make sure that:\n",
        "\n",
        "* You have completed all week 1 lectures or videos\n",
        "\n",
        "* You have completed Lab0 (MP0)\n",
        "\n",
        "* Chapter 2 of the text book would also be helpful\n",
        "\n",
        "### Instruction\n",
        "\n",
        "You should edit the code in `template.cu` to perform the following:\n",
        "\n",
        "* Allocate device memory\n",
        "\n",
        "* Copy host memory to device\n",
        "\n",
        "* Initialize thread block and kernel grid dimensions\n",
        "\n",
        "* Invoke CUDA kernel\n",
        "\n",
        "* Copy results from device to host\n",
        "\n",
        "* Free device memory\n",
        "\n",
        "* Write the CUDA kernel\n",
        "\n",
        "Instructions about where to place each part of the code is\n",
        "demarcated by the `//@@` comment lines.\n",
        "\n",
        "If your solution is correct, you should be able to see the following\n",
        "output for each of the 10 test datasets:\n",
        "```\n",
        "--------------\n",
        "Dataset  X\n",
        "The input length is XX\n",
        "Solution is correct\n",
        "```\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "K7IjtfWeHSBW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i6EE6p1-l6UT",
        "outputId": "4203e3d0-d8d8-4def-d393-03ab4b682c25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing mp1.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile mp1.cu\n",
        "#include \"/content/Parallel-Programming-Assignments/include/wb.h\"\n",
        "\n",
        "__global__ void vecAdd(float *in1, float *in2, float *out, int len) {\n",
        "\tint idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\tif (idx < len)\n",
        "\t\tout[idx] = in1[idx] + in2[idx];\n",
        "}\n",
        "\n",
        "int main(int argc, char **argv) {\n",
        "\twbArg_t args;\n",
        "\tint inputLength;\n",
        "\tfloat *hostInput1;\n",
        "\tfloat *hostInput2;\n",
        "\tfloat *hostOutput;\n",
        "\tfloat *deviceInput1;\n",
        "\tfloat *deviceInput2;\n",
        "\tfloat *deviceOutput;\n",
        "\n",
        "\targs = wbArg_read(argc, argv);\n",
        "\n",
        "\twbTime_start(Generic, \"Importing data and creating memory on host\");\n",
        "\thostInput1 = (float *)wbImport(wbArg_getInputFile(args, 0), &inputLength);\n",
        "\thostInput2 = (float *)wbImport(wbArg_getInputFile(args, 1), &inputLength);\n",
        "\thostOutput = (float *)malloc(inputLength * sizeof(float));\n",
        "\twbTime_stop(Generic, \"Importing data and creating memory on host\");\n",
        "\n",
        "\twbLog(TRACE, \"The input length is \", inputLength);\n",
        "\n",
        "\tint size = inputLength * sizeof(float);\n",
        "\n",
        "\twbTime_start(GPU, \"Allocating GPU memory.\");\n",
        "\tcudaMalloc((void **)&deviceInput1, size);\n",
        "\tcudaMalloc((void **)&deviceInput2, size);\n",
        "\tcudaMalloc((void **)&deviceOutput, size);\n",
        "\twbTime_stop(GPU, \"Allocating GPU memory.\");\n",
        "\n",
        "\twbTime_start(GPU, \"Copying input memory to the GPU.\");\n",
        "\tcudaMemcpy(deviceInput1, hostInput1, size, cudaMemcpyHostToDevice);\n",
        "\tcudaMemcpy(deviceInput2, hostInput2, size, cudaMemcpyHostToDevice);\n",
        "\twbTime_stop(GPU, \"Copying input memory to the GPU.\");\n",
        "\n",
        "\tdim3 DimGrid((inputLength - 1) / 256 + 1, 1, 1);\n",
        "\tdim3 DimBlock(256, 1, 1);\n",
        "\n",
        "\twbTime_start(Compute, \"Performing CUDA computation\");\n",
        "\tvecAdd << <DimGrid, DimBlock >> >(deviceInput1, deviceInput2, deviceOutput, inputLength);\n",
        "\n",
        "\tcudaDeviceSynchronize();\n",
        "\twbTime_stop(Compute, \"Performing CUDA computation\");\n",
        "\n",
        "\twbTime_start(Copy, \"Copying output memory to the CPU\");\n",
        "\tcudaMemcpy(hostOutput, deviceOutput, size, cudaMemcpyDeviceToHost);\n",
        "\twbTime_stop(Copy, \"Copying output memory to the CPU\");\n",
        "\n",
        "\twbTime_start(GPU, \"Freeing GPU Memory\");\n",
        "\tcudaFree(deviceInput1);\n",
        "\tcudaFree(deviceInput2);\n",
        "\tcudaFree(deviceOutput);\n",
        "\twbTime_stop(GPU, \"Freeing GPU Memory\");\n",
        "\n",
        "\twbSolution(args, hostOutput, inputLength);\n",
        "\n",
        "\tfree(hostInput1);\n",
        "\tfree(hostInput2);\n",
        "\tfree(hostOutput);\n",
        "\n",
        "\treturn 0;\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yO-R3Rbi_fWF",
        "outputId": "211e0f07-2b91-4264-8c12-c0a38d1a60a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running MP1\n",
            "\n",
            "======================================================================\n",
            "----------------------------------------------------------------------\n",
            "Test Case 0:\n",
            "----------------\n",
            "[Generic] 0.000239104 Importing data and creating memory on host\n",
            "Trace main::27 The input length is 64\n",
            "[GPU    ] 0.000155136 Allocating GPU memory.\n",
            "[GPU    ] 0.001193216 Copying input memory to the GPU.\n",
            "[Compute] 0.000037120 Performing CUDA computation\n",
            "[Copy   ] 0.000019968 Copying output memory to the CPU\n",
            "[GPU    ] 0.000145920 Freeing GPU Memory\n",
            "Solution is correct.\n",
            "----------------------------------------------------------------------\n",
            "Test Case 1:\n",
            "----------------\n",
            "[Generic] 0.000267776 Importing data and creating memory on host\n",
            "Trace main::27 The input length is 128\n",
            "[GPU    ] 0.000132096 Allocating GPU memory.\n",
            "[GPU    ] 0.000041216 Copying input memory to the GPU.\n",
            "[Compute] 0.000032768 Performing CUDA computation\n",
            "[Copy   ] 0.000019968 Copying output memory to the CPU\n",
            "[GPU    ] 0.000111872 Freeing GPU Memory\n",
            "Solution is correct.\n",
            "----------------------------------------------------------------------\n",
            "Test Case 2:\n",
            "----------------\n",
            "[Generic] 0.000179968 Importing data and creating memory on host\n",
            "Trace main::27 The input length is 56\n",
            "[GPU    ] 0.000125952 Allocating GPU memory.\n",
            "[GPU    ] 0.000040960 Copying input memory to the GPU.\n",
            "[Compute] 0.000030976 Performing CUDA computation\n",
            "[Copy   ] 0.000018944 Copying output memory to the CPU\n",
            "[GPU    ] 0.000100864 Freeing GPU Memory\n",
            "Solution is correct.\n",
            "----------------------------------------------------------------------\n",
            "Test Case 3:\n",
            "----------------\n",
            "[Generic] 0.000203008 Importing data and creating memory on host\n",
            "Trace main::27 The input length is 100\n",
            "[GPU    ] 0.000167936 Allocating GPU memory.\n",
            "[GPU    ] 0.000046080 Copying input memory to the GPU.\n",
            "[Compute] 0.000032000 Performing CUDA computation\n",
            "[Copy   ] 0.000022016 Copying output memory to the CPU\n",
            "[GPU    ] 0.000142848 Freeing GPU Memory\n",
            "Solution is correct.\n",
            "----------------------------------------------------------------------\n",
            "Test Case 4:\n",
            "----------------\n",
            "[Generic] 0.000378880 Importing data and creating memory on host\n",
            "Trace main::27 The input length is 256\n",
            "[GPU    ] 0.000148992 Allocating GPU memory.\n",
            "[GPU    ] 0.000038912 Copying input memory to the GPU.\n",
            "[Compute] 0.000046080 Performing CUDA computation\n",
            "[Copy   ] 0.000022016 Copying output memory to the CPU\n",
            "[GPU    ] 0.000111872 Freeing GPU Memory\n",
            "Solution is correct.\n",
            "----------------------------------------------------------------------\n",
            "Test Case 5:\n",
            "----------------\n",
            "[Generic] 0.000366080 Importing data and creating memory on host\n",
            "Trace main::27 The input length is 130\n",
            "[GPU    ] 0.000165120 Allocating GPU memory.\n",
            "[GPU    ] 0.000044032 Copying input memory to the GPU.\n",
            "[Compute] 0.000027904 Performing CUDA computation\n",
            "[Copy   ] 0.000019968 Copying output memory to the CPU\n",
            "[GPU    ] 0.000132096 Freeing GPU Memory\n",
            "Solution is correct.\n",
            "----------------------------------------------------------------------\n",
            "Test Case 6:\n",
            "----------------\n",
            "[Generic] 0.000286976 Importing data and creating memory on host\n",
            "Trace main::27 The input length is 90\n",
            "[GPU    ] 0.000171008 Allocating GPU memory.\n",
            "[GPU    ] 0.000040960 Copying input memory to the GPU.\n",
            "[Compute] 0.000033792 Performing CUDA computation\n",
            "[Copy   ] 0.000018944 Copying output memory to the CPU\n",
            "[GPU    ] 0.000123904 Freeing GPU Memory\n",
            "Solution is correct.\n",
            "----------------------------------------------------------------------\n",
            "Test Case 7:\n",
            "----------------\n",
            "[Generic] 0.000984064 Importing data and creating memory on host\n",
            "Trace main::27 The input length is 512\n",
            "[GPU    ] 0.000179968 Allocating GPU memory.\n",
            "[GPU    ] 0.000062976 Copying input memory to the GPU.\n",
            "[Compute] 0.000033024 Performing CUDA computation\n",
            "[Copy   ] 0.000020992 Copying output memory to the CPU\n",
            "[GPU    ] 0.000135936 Freeing GPU Memory\n",
            "Solution is correct.\n",
            "----------------------------------------------------------------------\n",
            "Test Case 8:\n",
            "----------------\n",
            "[Generic] 0.000320000 Importing data and creating memory on host\n",
            "Trace main::27 The input length is 90\n",
            "[GPU    ] 0.000190976 Allocating GPU memory.\n",
            "[GPU    ] 0.000043008 Copying input memory to the GPU.\n",
            "[Compute] 0.000029952 Performing CUDA computation\n",
            "[Copy   ] 0.000019968 Copying output memory to the CPU\n",
            "[GPU    ] 0.000158976 Freeing GPU Memory\n",
            "Solution is correct.\n",
            "----------------------------------------------------------------------\n",
            "Test Case 9:\n",
            "----------------\n",
            "[Generic] 0.000332800 Importing data and creating memory on host\n",
            "Trace main::27 The input length is 123\n",
            "[GPU    ] 0.000188928 Allocating GPU memory.\n",
            "[GPU    ] 0.000038144 Copying input memory to the GPU.\n",
            "[Compute] 0.000032000 Performing CUDA computation\n",
            "[Copy   ] 0.000019968 Copying output memory to the CPU\n",
            "[GPU    ] 0.000123904 Freeing GPU Memory\n",
            "Solution is correct.\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "build_and_run(assignment_no = 1, no_of_test_cases = 10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gXfQxHYSCJtX"
      },
      "source": [
        "## MP2 (Matrix Multiplication)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Objective\n",
        "\n",
        "The purpose of this lab is for you to practice with using the CUDA API by implementing a simple Matrix Multiply kernel and its associated host code as shown in the lectures.\n",
        "\n",
        "### Prerequisites\n",
        "\n",
        "Before starting this lab, make sure that:\n",
        "\n",
        "* You have completed all week 2 lectures or videos\n",
        "\n",
        "* You have completed Lab1 (MP1)\n",
        "\n",
        "### Instruction\n",
        "\n",
        "You should edit the code in `template.cu` to perform the following:\n",
        "\n",
        "* Allocate device memory\n",
        "\n",
        "* Copy host memory to device\n",
        "\n",
        "* Initialize thread block and kernel grid dimensions\n",
        "\n",
        "* Invoke CUDA kernel\n",
        "\n",
        "* Copy results from device to host\n",
        "\n",
        "* Free device memory\n",
        "\n",
        "* Write the CUDA kernel\n",
        "\n",
        "Instructions about where to place each part of the code is\n",
        "demarcated by the `//@@` comment lines.\n",
        "\n",
        "If your solution is correct, you should be able to see the\n",
        "following output for each of the 10 test datasets:\n",
        "```\n",
        "--------------\n",
        "Dataset  X\n",
        "The dimensions of A are X x X\n",
        "The dimensions of B are X x X\n",
        "...\n",
        "Solution is correct\n",
        "```\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "FjPxj6OVHaDd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W5S5vOurCJtX",
        "outputId": "f4cf46b8-ce4b-4107-b348-aea0a6bc6866"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing mp2.cu\n"
          ]
        }
      ],
      "source": [
        "  %%writefile mp2.cu\n",
        "  #include \"/content/Parallel-Programming-Assignments/include/wb.h\"\n",
        "\n",
        "  #define wbCheck(stmt)                                                     \\\n",
        "    do {                                                                    \\\n",
        "      cudaError_t err = stmt;                                               \\\n",
        "      if (err != cudaSuccess) {                                             \\\n",
        "        wbLog(ERROR, \"Failed to run stmt \", #stmt);                         \\\n",
        "        wbLog(ERROR, \"Got CUDA error ...  \", cudaGetErrorString(err));      \\\n",
        "        return -1;                                                          \\\n",
        "      }                                                                     \\\n",
        "    } while (0)\n",
        "\n",
        "  __global__ void matrixMultiply(float *A, float *B, float *C, int numARows,\n",
        "                                int numAColumns, int numBRows,\n",
        "                                int numBColumns, int numCRows,\n",
        "                                int numCColumns) {\n",
        "    //@@ Insert code to implement matrix multiplication here\n",
        "    int tx = threadIdx.x;\n",
        "    int ty = threadIdx.y;\n",
        "    int bx = blockIdx.x;\n",
        "    int by = blockIdx.y;\n",
        "    int Row = by * blockDim.y + ty;\n",
        "    int Col = bx * blockDim.x + tx;\n",
        "    float Cvalue = 0.0;\n",
        "\n",
        "    if (Row < numCRows && Col < numCColumns) {\n",
        "      for (int k = 0; k < numAColumns; ++k) {\n",
        "        Cvalue += A[Row * numAColumns + k] * B[k * numBColumns + Col];\n",
        "      }\n",
        "      C[Row * numCColumns + Col] = Cvalue;\n",
        "    }\n",
        "  }\n",
        "\n",
        "  int main(int argc, char **argv) {\n",
        "    wbArg_t args;\n",
        "    float *hostA; // The A matrix\n",
        "    float *hostB; // The B matrix\n",
        "    float *hostC; // The output C matrix\n",
        "    float *deviceA;\n",
        "    float *deviceB;\n",
        "    float *deviceC;\n",
        "    int numARows;    // number of rows in the matrix A\n",
        "    int numAColumns; // number of columns in the matrix A\n",
        "    int numBRows;    // number of rows in the matrix B\n",
        "    int numBColumns; // number of columns in the matrix B\n",
        "    int numCRows;    // number of rows in the matrix C (you have to set this)\n",
        "    int numCColumns; // number of columns in the matrix C (you have to set this)\n",
        "\n",
        "    args = wbArg_read(argc, argv);\n",
        "\n",
        "    wbTime_start(Generic, \"Importing data and creating memory on host\");\n",
        "    hostA = (float *)wbImport(wbArg_getInputFile(args, 0), &numARows, &numAColumns);\n",
        "    hostB = (float *)wbImport(wbArg_getInputFile(args, 1), &numBRows, &numBColumns);\n",
        "\n",
        "    //@@ Set numCRows and numCColumns\n",
        "    numCRows = numARows;\n",
        "    numCColumns = numBColumns;\n",
        "\n",
        "    //@@ Allocate the hostC matrix\n",
        "    hostC = (float *)malloc(numCRows * numCColumns * sizeof(float));\n",
        "    wbTime_stop(Generic, \"Importing data and creating memory on host\");\n",
        "\n",
        "    wbLog(TRACE, \"The dimensions of A are \", numARows, \" x \", numAColumns);\n",
        "    wbLog(TRACE, \"The dimensions of B are \", numBRows, \" x \", numBColumns);\n",
        "\n",
        "    wbTime_start(GPU, \"Allocating GPU memory.\");\n",
        "    //@@ Allocate GPU memory here\n",
        "    cudaMalloc((void **)&deviceA, numARows * numAColumns * sizeof(float));\n",
        "    cudaMalloc((void **)&deviceB, numBRows * numBColumns * sizeof(float));\n",
        "    cudaMalloc((void **)&deviceC, numCRows * numCColumns * sizeof(float));\n",
        "    wbTime_stop(GPU, \"Allocating GPU memory.\");\n",
        "\n",
        "    wbTime_start(GPU, \"Copying input memory to the GPU.\");\n",
        "    //@@ Copy memory to the GPU here\n",
        "    cudaMemcpy(deviceA, hostA, numARows * numAColumns * sizeof(float), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(deviceB, hostB, numBRows * numBColumns * sizeof(float), cudaMemcpyHostToDevice);\n",
        "    wbTime_stop(GPU, \"Copying input memory to the GPU.\");\n",
        "\n",
        "    //@@ Initialize the grid and block dimensions here\n",
        "    dim3 blockDim(16, 16);\n",
        "    dim3 gridDim((numCColumns + blockDim.x - 1) / blockDim.x, (numCRows + blockDim.y - 1) / blockDim.y);\n",
        "\n",
        "    wbTime_start(Compute, \"Performing CUDA computation\");\n",
        "    //@@ Launch the GPU Kernel here\n",
        "    matrixMultiply<<<gridDim, blockDim>>>(deviceA, deviceB, deviceC, numARows, numAColumns, numBRows, numBColumns, numCRows, numCColumns);\n",
        "    cudaDeviceSynchronize();\n",
        "    wbTime_stop(Compute, \"Performing CUDA computation\");\n",
        "\n",
        "    wbTime_start(Copy, \"Copying output memory to the CPU\");\n",
        "    //@@ Copy the GPU memory back to the CPU here\n",
        "    cudaMemcpy(hostC, deviceC, numCRows * numCColumns * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "    wbTime_stop(Copy, \"Copying output memory to the CPU\");\n",
        "\n",
        "    wbTime_start(GPU, \"Freeing GPU Memory\");\n",
        "    //@@ Free the GPU memory here\n",
        "    cudaFree(deviceA);\n",
        "    cudaFree(deviceB);\n",
        "    cudaFree(deviceC);\n",
        "    wbTime_stop(GPU, \"Freeing GPU Memory\");\n",
        "\n",
        "    wbSolution(args, hostC, numCRows, numCColumns);\n",
        "\n",
        "    free(hostA);\n",
        "    free(hostB);\n",
        "    free(hostC);\n",
        "\n",
        "    return 0;\n",
        "  }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AWI7_ij5CJtY",
        "outputId": "fe0b1fe6-c136-4f6e-cc35-84806b69b817"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running MP2\n",
            "\n",
            "======================================================================\n",
            "----------------------------------------------------------------------\n",
            "Test Case 0:\n",
            "----------------\n",
            "[Generic] 0.003546880 Importing data and creating memory on host\n",
            "Trace main::63 The dimensions of A are 64 x 64\n",
            "Trace main::64 The dimensions of B are 64 x 64\n",
            "[GPU    ] 0.000180992 Allocating GPU memory.\n",
            "[GPU    ] 0.000057856 Copying input memory to the GPU.\n",
            "[Compute] 0.000034816 Performing CUDA computation\n",
            "[Copy   ] 0.000027904 Copying output memory to the CPU\n",
            "[GPU    ] 0.000111872 Freeing GPU Memory\n",
            "Solution is correct.\n",
            "----------------------------------------------------------------------\n",
            "Test Case 1:\n",
            "----------------\n",
            "[Generic] 0.007094016 Importing data and creating memory on host\n",
            "Trace main::63 The dimensions of A are 128 x 64\n",
            "Trace main::64 The dimensions of B are 64 x 128\n",
            "[GPU    ] 0.000133120 Allocating GPU memory.\n",
            "[GPU    ] 0.000068864 Copying input memory to the GPU.\n",
            "[Compute] 0.000040960 Performing CUDA computation\n",
            "[Copy   ] 0.000077824 Copying output memory to the CPU\n",
            "[GPU    ] 0.000110080 Freeing GPU Memory\n",
            "Solution is correct.\n",
            "----------------------------------------------------------------------\n",
            "Test Case 2:\n",
            "----------------\n",
            "[Generic] 0.008489984 Importing data and creating memory on host\n",
            "Trace main::63 The dimensions of A are 100 x 128\n",
            "Trace main::64 The dimensions of B are 128 x 56\n",
            "[GPU    ] 0.000134912 Allocating GPU memory.\n",
            "[GPU    ] 0.000075776 Copying input memory to the GPU.\n",
            "[Compute] 0.000047104 Performing CUDA computation\n",
            "[Copy   ] 0.000026880 Copying output memory to the CPU\n",
            "[GPU    ] 0.000110080 Freeing GPU Memory\n",
            "Solution is correct.\n",
            "----------------------------------------------------------------------\n",
            "Test Case 3:\n",
            "----------------\n",
            "[Generic] 0.006998784 Importing data and creating memory on host\n",
            "Trace main::63 The dimensions of A are 128 x 64\n",
            "Trace main::64 The dimensions of B are 64 x 128\n",
            "[GPU    ] 0.000134912 Allocating GPU memory.\n",
            "[GPU    ] 0.000066048 Copying input memory to the GPU.\n",
            "[Compute] 0.000045056 Performing CUDA computation\n",
            "[Copy   ] 0.000080128 Copying output memory to the CPU\n",
            "[GPU    ] 0.000112896 Freeing GPU Memory\n",
            "Solution is correct.\n",
            "----------------------------------------------------------------------\n",
            "Test Case 4:\n",
            "----------------\n",
            "[Generic] 0.003684864 Importing data and creating memory on host\n",
            "Trace main::63 The dimensions of A are 32 x 128\n",
            "Trace main::64 The dimensions of B are 128 x 32\n",
            "[GPU    ] 0.000150016 Allocating GPU memory.\n",
            "[GPU    ] 0.000054016 Copying input memory to the GPU.\n",
            "[Compute] 0.000058112 Performing CUDA computation\n",
            "[Copy   ] 0.000022016 Copying output memory to the CPU\n",
            "[GPU    ] 0.000112896 Freeing GPU Memory\n",
            "Solution is correct.\n",
            "----------------------------------------------------------------------\n",
            "Test Case 5:\n",
            "----------------\n",
            "[Generic] 0.034923008 Importing data and creating memory on host\n",
            "Trace main::63 The dimensions of A are 200 x 100\n",
            "Trace main::64 The dimensions of B are 100 x 256\n",
            "[GPU    ] 0.000253952 Allocating GPU memory.\n",
            "[GPU    ] 0.000120064 Copying input memory to the GPU.\n",
            "[Compute] 0.000079872 Performing CUDA computation\n",
            "[Copy   ] 0.000201984 Copying output memory to the CPU\n",
            "[GPU    ] 0.000178944 Freeing GPU Memory\n",
            "Solution is correct.\n",
            "----------------------------------------------------------------------\n",
            "Test Case 6:\n",
            "----------------\n",
            "[Generic] 0.111806976 Importing data and creating memory on host\n",
            "Trace main::63 The dimensions of A are 256 x 256\n",
            "Trace main::64 The dimensions of B are 256 x 256\n",
            "[GPU    ] 0.000218880 Allocating GPU memory.\n",
            "[GPU    ] 0.000198912 Copying input memory to the GPU.\n",
            "[Compute] 0.000185088 Performing CUDA computation\n",
            "[Copy   ] 0.000107008 Copying output memory to the CPU\n",
            "[GPU    ] 0.000148992 Freeing GPU Memory\n",
            "Solution is correct.\n",
            "----------------------------------------------------------------------\n",
            "Test Case 7:\n",
            "----------------\n",
            "[Generic] 0.133985024 Importing data and creating memory on host\n",
            "Trace main::63 The dimensions of A are 256 x 300\n",
            "Trace main::64 The dimensions of B are 300 x 256\n",
            "[GPU    ] 0.000220928 Allocating GPU memory.\n",
            "[GPU    ] 0.000239104 Copying input memory to the GPU.\n",
            "[Compute] 0.000205824 Performing CUDA computation\n",
            "[Copy   ] 0.000096000 Copying output memory to the CPU\n",
            "[GPU    ] 0.000162048 Freeing GPU Memory\n",
            "Solution is correct.\n",
            "----------------------------------------------------------------------\n",
            "Test Case 8:\n",
            "----------------\n",
            "[Generic] 0.014843136 Importing data and creating memory on host\n",
            "Trace main::63 The dimensions of A are 64 x 128\n",
            "Trace main::64 The dimensions of B are 128 x 64\n",
            "[GPU    ] 0.000166912 Allocating GPU memory.\n",
            "[GPU    ] 0.000067072 Copying input memory to the GPU.\n",
            "[Compute] 0.000039936 Performing CUDA computation\n",
            "[Copy   ] 0.000025088 Copying output memory to the CPU\n",
            "[GPU    ] 0.000297984 Freeing GPU Memory\n",
            "Solution is correct.\n",
            "----------------------------------------------------------------------\n",
            "Test Case 9:\n",
            "----------------\n",
            "[Generic] 0.115558912 Importing data and creating memory on host\n",
            "Trace main::63 The dimensions of A are 256 x 256\n",
            "Trace main::64 The dimensions of B are 256 x 257\n",
            "[GPU    ] 0.000274176 Allocating GPU memory.\n",
            "[GPU    ] 0.000230912 Copying input memory to the GPU.\n",
            "[Compute] 0.000897024 Performing CUDA computation\n",
            "[Copy   ] 0.000111872 Copying output memory to the CPU\n",
            "[GPU    ] 0.000190208 Freeing GPU Memory\n",
            "Solution is correct.\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "build_and_run(assignment_no = 2, no_of_test_cases = 10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_IJAyd9OCJtY"
      },
      "source": [
        "## MP3 (Tiled Matrix Multiplication)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Objective\n",
        "\n",
        "The purpose of this lab is for you to practice with using the CUDA API by implementing a tiled Matrix Multiply kernel and its associated host code as shown in the lectures.\n",
        "\n",
        "### Prerequisites\n",
        "\n",
        "Before starting this lab, make sure that:\n",
        "\n",
        "* You have completed all week 2 lectures or videos\n",
        "\n",
        "* You have completed Lab2 (MP2)\n",
        "\n",
        "### Instruction\n",
        "\n",
        "You should edit the code in `template.cu` to perform the following:\n",
        "\n",
        "* Allocate device memory\n",
        "\n",
        "* Copy host memory to device\n",
        "\n",
        "* Initialize thread block and kernel grid dimensions\n",
        "\n",
        "* Invoke CUDA kernel\n",
        "\n",
        "* Copy results from device to host\n",
        "\n",
        "* Free device memory\n",
        "\n",
        "* Write the CUDA kernel\n",
        "\n",
        "Instructions about where to place each part of the code is\n",
        "demarcated by the `//@@` comment lines.\n",
        "\n",
        "If your solution is correct, you should be able to see the\n",
        "following output for each of the 10 test datasets:\n",
        "```\n",
        "--------------\n",
        "Dataset  X\n",
        "The dimensions of A are X x X\n",
        "The dimensions of B are X x X\n",
        "...\n",
        "Solution is correct\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "W4mwBFntHfOF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_KU2BaToCJtY",
        "outputId": "2e3761a0-491c-4942-c9ca-bc0e7204b1e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing mp3.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile mp3.cu\n",
        "#include \"/content/Parallel-Programming-Assignments/include/wb.h\"\n",
        "\n",
        "#define wbCheck(stmt)                                                     \\\n",
        "  do {                                                                    \\\n",
        "    cudaError_t err = stmt;                                               \\\n",
        "    if (err != cudaSuccess) {                                             \\\n",
        "      wbLog(ERROR, \"Failed to run stmt \", #stmt);                         \\\n",
        "      wbLog(ERROR, \"Got CUDA error ...  \", cudaGetErrorString(err));      \\\n",
        "      return -1;                                                          \\\n",
        "    }                                                                     \\\n",
        "  } while (0)\n",
        "\n",
        "#define TILE_SIZE 16\n",
        "\n",
        "__global__ void matrixMultiply(float *A, float *B, float *C, int numARows,\n",
        "                               int numAColumns, int numBRows,\n",
        "                               int numBColumns, int numCRows,\n",
        "                               int numCColumns) {\n",
        "\n",
        "  __shared__ float tileA[TILE_SIZE][TILE_SIZE];\n",
        "  __shared__ float tileB[TILE_SIZE][TILE_SIZE];\n",
        "\n",
        "  int tx = threadIdx.x;\n",
        "  int ty = threadIdx.y;\n",
        "  int bx = blockIdx.x;\n",
        "  int by = blockIdx.y;\n",
        "  int Row = by * blockDim.y + ty;\n",
        "  int Col = bx * blockDim.x + tx;\n",
        "  float Cvalue = 0.0;\n",
        "\n",
        "\n",
        "  for (int t = 0; t < (numAColumns - 1) / TILE_SIZE + 1; ++t) {\n",
        "\n",
        "    if (Row < numARows && (t * TILE_SIZE + tx) < numAColumns) {\n",
        "      tileA[ty][tx] = A[Row * numAColumns + t * TILE_SIZE + tx];\n",
        "\n",
        "    } else {\n",
        "      tileA[ty][tx] = 0.0;\n",
        "    }\n",
        "\n",
        "    if ((t * TILE_SIZE + ty) < numBRows && Col < numBColumns) {\n",
        "      tileB[ty][tx] = B[(t * TILE_SIZE + ty) * numBColumns + Col];\n",
        "\n",
        "    } else {\n",
        "      tileB[ty][tx] = 0.0;\n",
        "    }\n",
        "\n",
        "    __syncthreads();\n",
        "\n",
        "\n",
        "    for (int k = 0; k < TILE_SIZE; ++k) {\n",
        "      Cvalue += tileA[ty][k] * tileB[k][tx];\n",
        "    }\n",
        "\n",
        "    __syncthreads();\n",
        "  }\n",
        "\n",
        "\n",
        "  if (Row < numCRows && Col < numCColumns) {\n",
        "    C[Row * numCColumns + Col] = Cvalue;\n",
        "  }\n",
        "}\n",
        "\n",
        "int main(int argc, char **argv) {\n",
        "  wbArg_t args;\n",
        "  float *hostA; // The A matrix\n",
        "  float *hostB; // The B matrix\n",
        "  float *hostC; // The output C matrix\n",
        "  float *deviceA;\n",
        "  float *deviceB;\n",
        "  float *deviceC;\n",
        "  int numARows;    // number of rows in the matrix A\n",
        "  int numAColumns; // number of columns in the matrix A\n",
        "  int numBRows;    // number of rows in the matrix B\n",
        "  int numBColumns; // number of columns in the matrix B\n",
        "  int numCRows;    // number of rows in the matrix C (you have to set this)\n",
        "  int numCColumns; // number of columns in the matrix C (you have to set\n",
        "                   // this)\n",
        "\n",
        "  args = wbArg_read(argc, argv);\n",
        "\n",
        "  wbTime_start(Generic, \"Importing data and creating memory on host\");\n",
        "  hostA = (float *)wbImport(wbArg_getInputFile(args, 0), &numARows,\n",
        "                            &numAColumns);\n",
        "  hostB = (float *)wbImport(wbArg_getInputFile(args, 1), &numBRows,\n",
        "                            &numBColumns);\n",
        "  //@@ Set numCRows and numCColumns\n",
        "  numCRows = numARows;\n",
        "  numCColumns = numBColumns;\n",
        "  //@@ Allocate the hostC matrix\n",
        "  hostC = (float *)malloc(numCRows * numCColumns * sizeof(float));\n",
        "  wbTime_stop(Generic, \"Importing data and creating memory on host\");\n",
        "\n",
        "  wbLog(TRACE, \"The dimensions of A are \", numARows, \" x \", numAColumns);\n",
        "  wbLog(TRACE, \"The dimensions of B are \", numBRows, \" x \", numBColumns);\n",
        "\n",
        "  wbTime_start(GPU, \"Allocating GPU memory.\");\n",
        "  //@@ Allocate GPU memory here\n",
        "  cudaMalloc((void **)&deviceA, numARows * numAColumns * sizeof(float));\n",
        "  cudaMalloc((void **)&deviceB, numBRows * numBColumns * sizeof(float));\n",
        "  cudaMalloc((void **)&deviceC, numCRows * numCColumns * sizeof(float));\n",
        "  wbTime_stop(GPU, \"Allocating GPU memory.\");\n",
        "\n",
        "  wbTime_start(GPU, \"Copying input memory to the GPU.\");\n",
        "  //@@ Copy memory to the GPU here\n",
        "  cudaMemcpy(deviceA, hostA, numARows * numAColumns * sizeof(float), cudaMemcpyHostToDevice);\n",
        "  cudaMemcpy(deviceB, hostB, numBRows * numBColumns * sizeof(float), cudaMemcpyHostToDevice);\n",
        "  wbTime_stop(GPU, \"Copying input memory to the GPU.\");\n",
        "\n",
        "  //@@ Initialize the grid and block dimensions here\n",
        "  dim3 blockDim(TILE_SIZE, TILE_SIZE); // Use TILE_SIZE as the block size\n",
        "  dim3 gridDim((numCColumns + TILE_SIZE - 1) / TILE_SIZE, (numCRows + TILE_SIZE - 1) / TILE_SIZE);\n",
        "\n",
        "  wbTime_start(Compute, \"Performing CUDA computation\");\n",
        "  //@@ Launch the GPU Kernel here\n",
        "  matrixMultiply<<<gridDim, blockDim>>>(deviceA, deviceB, deviceC, numARows, numAColumns, numBRows, numBColumns, numCRows, numCColumns);\n",
        "  cudaDeviceSynchronize();\n",
        "  wbTime_stop(Compute, \"Performing CUDA computation\");\n",
        "\n",
        "  wbTime_start(Copy, \"Copying output memory to the CPU\");\n",
        "  //@@ Copy the GPU memory back to the CPU here\n",
        "  cudaMemcpy(hostC, deviceC, numCRows * numCColumns * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "  wbTime_stop(Copy, \"Copying output memory to the CPU\");\n",
        "\n",
        "  wbTime_start(GPU, \"Freeing GPU Memory\");\n",
        "  //@@ Free the GPU memory here\n",
        "  cudaFree(deviceA);\n",
        "  cudaFree(deviceB);\n",
        "  cudaFree(deviceC);\n",
        "  wbTime_stop(GPU, \"Freeing GPU Memory\");\n",
        "\n",
        "  wbSolution(args, hostC, numCRows, numCColumns);\n",
        "\n",
        "  free(hostA);\n",
        "  free(hostB);\n",
        "  free(hostC);\n",
        "\n",
        "  return 0;\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTtacQBpCJtY",
        "outputId": "44ab2a8e-991a-41c8-bd09-c1271fcd1824"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running MP3\n",
            "\n",
            "======================================================================\n",
            "----------------------------------------------------------------------\n",
            "Test Case 0:\n",
            "----------------\n",
            "[Generic] 0.003866112 Importing data and creating memory on host\n",
            "Trace main::94 The dimensions of A are 64 x 64\n",
            "Trace main::95 The dimensions of B are 64 x 64\n",
            "[GPU    ] 0.000178176 Allocating GPU memory.\n",
            "[GPU    ] 0.000058112 Copying input memory to the GPU.\n",
            "[Compute] 0.000041984 Performing CUDA computation\n",
            "[Copy   ] 0.000027904 Copying output memory to the CPU\n",
            "[GPU    ] 0.000118016 Freeing GPU Memory\n",
            "Solution is correct.\n",
            "----------------------------------------------------------------------\n",
            "Test Case 1:\n",
            "----------------\n",
            "[Generic] 0.007862016 Importing data and creating memory on host\n",
            "Trace main::94 The dimensions of A are 128 x 64\n",
            "Trace main::95 The dimensions of B are 64 x 128\n",
            "[GPU    ] 0.000143104 Allocating GPU memory.\n",
            "[GPU    ] 0.000080896 Copying input memory to the GPU.\n",
            "[Compute] 0.000040960 Performing CUDA computation\n",
            "[Copy   ] 0.000089088 Copying output memory to the CPU\n",
            "[GPU    ] 0.000121088 Freeing GPU Memory\n",
            "Solution is correct.\n",
            "----------------------------------------------------------------------\n",
            "Test Case 2:\n",
            "----------------\n",
            "[Generic] 0.010457856 Importing data and creating memory on host\n",
            "Trace main::94 The dimensions of A are 100 x 128\n",
            "Trace main::95 The dimensions of B are 128 x 56\n",
            "[GPU    ] 0.000148992 Allocating GPU memory.\n",
            "[GPU    ] 0.000080896 Copying input memory to the GPU.\n",
            "[Compute] 0.000043008 Performing CUDA computation\n",
            "[Copy   ] 0.000027904 Copying output memory to the CPU\n",
            "[GPU    ] 0.000150016 Freeing GPU Memory\n",
            "Solution is correct.\n",
            "----------------------------------------------------------------------\n",
            "Test Case 3:\n",
            "----------------\n",
            "[Generic] 0.006834944 Importing data and creating memory on host\n",
            "Trace main::94 The dimensions of A are 128 x 64\n",
            "Trace main::95 The dimensions of B are 64 x 128\n",
            "[GPU    ] 0.000139776 Allocating GPU memory.\n",
            "[GPU    ] 0.000077056 Copying input memory to the GPU.\n",
            "[Compute] 0.000043008 Performing CUDA computation\n",
            "[Copy   ] 0.000076032 Copying output memory to the CPU\n",
            "[GPU    ] 0.000110080 Freeing GPU Memory\n",
            "Solution is correct.\n",
            "----------------------------------------------------------------------\n",
            "Test Case 4:\n",
            "----------------\n",
            "[Generic] 0.003603968 Importing data and creating memory on host\n",
            "Trace main::94 The dimensions of A are 32 x 128\n",
            "Trace main::95 The dimensions of B are 128 x 32\n",
            "[GPU    ] 0.000128000 Allocating GPU memory.\n",
            "[GPU    ] 0.000056832 Copying input memory to the GPU.\n",
            "[Compute] 0.000038912 Performing CUDA computation\n",
            "[Copy   ] 0.000022016 Copying output memory to the CPU\n",
            "[GPU    ] 0.000102912 Freeing GPU Memory\n",
            "Solution is correct.\n",
            "----------------------------------------------------------------------\n",
            "Test Case 5:\n",
            "----------------\n",
            "[Generic] 0.019794944 Importing data and creating memory on host\n",
            "Trace main::94 The dimensions of A are 200 x 100\n",
            "Trace main::95 The dimensions of B are 100 x 256\n",
            "[GPU    ] 0.000135936 Allocating GPU memory.\n",
            "[GPU    ] 0.000099840 Copying input memory to the GPU.\n",
            "[Compute] 0.000069888 Performing CUDA computation\n",
            "[Copy   ] 0.000182784 Copying output memory to the CPU\n",
            "[GPU    ] 0.000121088 Freeing GPU Memory\n",
            "Solution is correct.\n",
            "----------------------------------------------------------------------\n",
            "Test Case 6:\n",
            "----------------\n",
            "[Generic] 0.060038144 Importing data and creating memory on host\n",
            "Trace main::94 The dimensions of A are 256 x 256\n",
            "Trace main::95 The dimensions of B are 256 x 256\n",
            "[GPU    ] 0.000140032 Allocating GPU memory.\n",
            "[GPU    ] 0.000193024 Copying input memory to the GPU.\n",
            "[Compute] 0.000132864 Performing CUDA computation\n",
            "[Copy   ] 0.000095232 Copying output memory to the CPU\n",
            "[GPU    ] 0.000119040 Freeing GPU Memory\n",
            "Solution is correct.\n",
            "----------------------------------------------------------------------\n",
            "Test Case 7:\n",
            "----------------\n",
            "[Generic] 0.079201024 Importing data and creating memory on host\n",
            "Trace main::94 The dimensions of A are 256 x 300\n",
            "Trace main::95 The dimensions of B are 300 x 256\n",
            "[GPU    ] 0.000168960 Allocating GPU memory.\n",
            "[GPU    ] 0.000232960 Copying input memory to the GPU.\n",
            "[Compute] 0.000154880 Performing CUDA computation\n",
            "[Copy   ] 0.000096000 Copying output memory to the CPU\n",
            "[GPU    ] 0.000132096 Freeing GPU Memory\n",
            "Solution is correct.\n",
            "----------------------------------------------------------------------\n",
            "Test Case 8:\n",
            "----------------\n",
            "[Generic] 0.007310080 Importing data and creating memory on host\n",
            "Trace main::94 The dimensions of A are 64 x 128\n",
            "Trace main::95 The dimensions of B are 128 x 64\n",
            "[GPU    ] 0.000148992 Allocating GPU memory.\n",
            "[GPU    ] 0.000067072 Copying input memory to the GPU.\n",
            "[Compute] 0.000036864 Performing CUDA computation\n",
            "[Copy   ] 0.000025088 Copying output memory to the CPU\n",
            "[GPU    ] 0.000110080 Freeing GPU Memory\n",
            "Solution is correct.\n",
            "----------------------------------------------------------------------\n",
            "Test Case 9:\n",
            "----------------\n",
            "[Generic] 0.061615872 Importing data and creating memory on host\n",
            "Trace main::94 The dimensions of A are 256 x 256\n",
            "Trace main::95 The dimensions of B are 256 x 257\n",
            "[GPU    ] 0.000169216 Allocating GPU memory.\n",
            "[GPU    ] 0.000200960 Copying input memory to the GPU.\n",
            "[Compute] 0.000134912 Performing CUDA computation\n",
            "[Copy   ] 0.000097024 Copying output memory to the CPU\n",
            "[GPU    ] 0.000132096 Freeing GPU Memory\n",
            "Solution is correct.\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "build_and_run(assignment_no = 3, no_of_test_cases = 10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZvERCbgCJtY"
      },
      "source": [
        "## MP4"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Objective\n",
        "\n",
        "The purpose of this lab is for you to practice with using the CUDA API by implementing a 3D Convolution kernel and its associated host code as shown in the lectures.\n",
        "\n",
        "### Prerequisites\n",
        "\n",
        "Before starting this lab, make sure that:\n",
        "\n",
        "* You have completed all week 4 lectures or videos\n",
        "\n",
        "* You have completed Lab3 (MP3)\n",
        "\n",
        "### Instruction\n",
        "\n",
        "You should edit the code in `template.cu` to perform the following:\n",
        "\n",
        "* Allocate device memory\n",
        "\n",
        "* Copy host memory to device\n",
        "\n",
        "* Initialize thread block and kernel grid dimensions\n",
        "\n",
        "* Invoke CUDA kernel\n",
        "\n",
        "* Copy results from device to host\n",
        "\n",
        "* Free device memory\n",
        "\n",
        "* Write the CUDA kernel\n",
        "\n",
        "If your solution is correct, you should be able to see the\n",
        "following output for each of the 10 test datasets:\n",
        "```\n",
        "--------------\n",
        "Dataset  X\n",
        "The input size is XxYxZ\n",
        "Solution is correct\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "1WHjj4FFHkmk"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": [],
      "collapsed_sections": [
        "sxr9NntDCJtV",
        "K4Vv1jKmCJtW",
        "gXfQxHYSCJtX",
        "_IJAyd9OCJtY"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}